[
  {
    "objectID": "posts/2019-10-31.html",
    "href": "posts/2019-10-31.html",
    "title": "gganimate (with a spooky twist)",
    "section": "",
    "text": "gganimate allows for the animation of ggplot2 graphics. The package has been around for a while, but it has been updated to allow for easier transitions from static ggplot2 graphic to animated versions. This talk is meant to be an interactive tutorial on how to use the updated version of gganimate. You are encouraged to bring a laptop to follow along. Since the talk will be given on Halloween, spooky datasets will be used to demonstrate the functionality of gganimate.\nSlides GitHub"
  },
  {
    "objectID": "posts/2019-07-29.html",
    "href": "posts/2019-07-29.html",
    "title": "Visual Diagnostics of a Model Explainer: Tools for the Assessment of LIME Explanations from Random Forests",
    "section": "",
    "text": "Random forests are known for their accurate predictive abilities, but they are a part of the family of machine learning models that lack interpretability. A technique called LIME was developed to provide local interpretations for predictive models. The technique fits a ridge regression model to binary encoded perturbations created from the observed data weighted by proximity to the prediction of interest. The predicted values associated with the perturbations computed using the complex model are used as the response variable in the regression. The coefficients from the linear model are then used to determine the influential variables. We have developed some visualizations and other diagnostic tools to assess the explanations produced by LIME from a random forest. In particular, we consider how well the simple model fit by LIME captures the random forest model and how the results from LIME vary based on different algorithm input options. To demonstrate these tools, we apply LIME to a random forest fit to a forensics bullet matching dataset using the lime R package and apply our methods to diagnose the LIME explanations.\nSlides Poster GitHub"
  },
  {
    "objectID": "posts/2019-05-13.html",
    "href": "posts/2019-05-13.html",
    "title": "Using LIME to Interpret a Random Forest Model with an Application to Bullet Matching Data",
    "section": "",
    "text": "Also presented on April 10, 2019 at the Iowa State University Graduate and Professional Student Research Conference\nRandom forests are known for their accurate predictive abilities, but they are a part of the family of machine learning models that lack interpretability. Recently, a technique called LIME was developed to provide local interpretations for complex predictive models. LIME determines which variables are important in a prediction of interest by fitting a local linear regression to model predictions and perturbations of the data. The coefficients from the linear model are used to interpret the complex model. While applying LIME to random forests, I encountered some unusual results. This led me to develop some diagnostic tools to evaluate LIME. I will demonstrate these by assessing the application of LIME to a random forest fit to a forensics bullet matching dataset.\nPoster GitHub"
  },
  {
    "objectID": "posts/2021-02-25.html",
    "href": "posts/2021-02-25.html",
    "title": "WhoseEgg: A Shiny App for Identifying Invasive Carp Using Random Forests and Fish Egg Characteristics",
    "section": "",
    "text": "The fish species of Grass Carp (Ctenopharyngodon idella), Silver Carp (Hypophthalmichthys molitrix), and Bighead Carp (H. nobilis) are categorized as invasive carp in North America. There is interest from a natural resource management perspective to monitor the populations and spread of the fish species. A common monitoring practice is to collect and genetically identify fish eggs, but this process is both costly in money and time. Camacho et al. (2019) demonstrated the use of machine learning as a possibility for a more efficient method of identifying invasive carp. Camacho et al. (2019) trained random forests on easy to measure egg characteristics such as water conductivity and average membrane diameter, and the models returned high accuracy.\nIn this talk, I will present my recent work with Dr. Michael Weber (NREM) and Dr. Philip Dixon on a Shiny app (WhoseEgg) for identifying invasive carp using random forests based on those from Camacho et al. (2019). The app is intended to be a tool for researchers to input their own fish egg data and easily obtain random forest predictions via a point-and-click user interface. We began work on the app in January, so it is still in development. I will share the current state of the app and our goals for enhancement. I will also ask the audience for feedback. We would greatly appreciate suggestions for adjustments to make the app more user friendly.\nSlides GitHub"
  },
  {
    "objectID": "posts/2020-11-16.html",
    "href": "posts/2020-11-16.html",
    "title": "The Delta Method and Applications to Mark Recapture Models",
    "section": "",
    "text": "This talk discusses the delta method and ways to apply it in R.\nSlides GitHub"
  },
  {
    "objectID": "posts/2020-11-14.html",
    "href": "posts/2020-11-14.html",
    "title": "Explaining Neural Networks with Functional Data Using PCA and Feature Importance",
    "section": "",
    "text": "Optical spectral-temporal signatures extracted from videos of explosions provide information for identifying characteristics of the corresponding explosive devices. Currently, the identification is done using heuristic algorithms and direct subject matter expert review. An improvement in predictive performance may be obtained by using machine learning, but this application lends itself to high consequence national security decisions, so it is not only important to provide high accuracy but clear explanations for the predictions to garner confidence in the model. While much work has been done to develop explainability methods for machine learning models, not much of the work focuses on situations with input variables of the form of functional data such optical spectral-temporal signatures. We propose a procedure for explaining machine learning models fit using functional data that accounts for the functional nature the data. Our approach makes use of functional principal component analysis (fPCA) and permutation feature importance (PFI). fPCA is used to transform the functions to create uncorrelated functional principal components (fPCs). The model is trained using the fPCs as inputs, and PFI is applied to identify the fPCs important to the model for prediction. Visualizations are used to interpret the variability explained by the fPCs that are found to be important by PFI to determine the aspects of the functions that are important for prediction. We demonstrate the technique by explaining neural networks fit to explosion optical spectral-temporal signatures for predicting characteristics of the explosive devices.\nSandia National Laboratories is a multimission laboratory managed and operated by National Technology & Engineering Solutions of Sandia, LLC, a wholly owned subsidiary of Honeywell International Inc., for the U.S. Department of Energy’s National Nuclear Security Administration under contract DE-NA0003525. This paper describes objective technical results and analysis. Any subjective views or opinions that might be expressed in the paper do not necessarily represent the views of the U.S. Department of Energy or the United States Government. SAND2020-12004 C\nSlides Recording Paper"
  },
  {
    "objectID": "posts/2019-06-20.html",
    "href": "posts/2019-06-20.html",
    "title": "A Review and Discussion of Residuals for Mixed Models",
    "section": "",
    "text": "Residuals are a key tool used to diagnose models. As a statistical consultant for researchers in many areas, I often find myself reminding my clients to visualize residuals to assess model assumptions. Many of my clients are working with mixed models, and I recently realized that I often recommend the use of certain residual types without a full understanding of the implications of selecting one type over another. This led me to have an interest in better understanding the many residuals types for mixed model. In this talk, I will provide a review of the residual types available for linear mixed models (marginal, conditional, studentized, etc.). I will explain how the residuals are computed and how these computations differ between R and SAS. I will also discuss what I have learned from the literature about how to select a residual type when assessing a model. Lastly, I will briefly touch on residual types for generalized linear mixed models and list some unanswered questions. If time permits, I will pose these remaining questions to the attendees to discuss as a group.\nSlides GitHub"
  },
  {
    "objectID": "posts/2019-03-01.html",
    "href": "posts/2019-03-01.html",
    "title": "An Application of LIME to a Random Forest Model",
    "section": "",
    "text": "Random forests are known for their accurate predictive abilities, but they are a part of the family of machine learning models that lack interpretability. A technique called LIME was developed to provide local interpretations for black-box predictive models. In this talk, I will explain the LIME procedure and show an application of LIME to predictions from a random forest model fit to a bullet matching dataset. I will present a Shiny app I created to view the LIME explanations. Additionally, I will discuss the issues that I have encountered while working with LIME, some of the attempts at a solution, and future directions for my research.\nSlides GitHub"
  },
  {
    "objectID": "posts/2017-11-09.html",
    "href": "posts/2017-11-09.html",
    "title": "Tensor on tensor regression",
    "section": "",
    "text": "this is an abstract\nSlides GitHub"
  },
  {
    "objectID": "posts/2020-09-24.html",
    "href": "posts/2020-09-24.html",
    "title": "Explaining Neural Network Predictions for Functional Data Using Principal Component Analysis and Feature Importance",
    "section": "",
    "text": "Explainable machine learning has become a quickly growing area of research as the use of black-box models continues to increase. While many methods have been proposed, little research has been done relating to applications involving functional data. As an intern at Sandia National Laboratories, I have been helping to develop methods to provide explanations for an application focused on predicting explosive device characteristics using optical spectral-temporal signatures from explosions. In this talk, I’ll discuss our approach that involves transforming the functions using functional principal component analysis, training neural networks on the functional principal components, and using permutation feature importance (PFI) to identify the principal components that are important for prediction. Visualization has played a key role in the interpretation of the functional principal components identified as important by PFI to understand the functional variability in the signatures that is driving the predictions made by the neural networks.\nSandia National Laboratories is a multimission laboratory managed and operated by National Technology & Engineering Solutions of Sandia, LLC, a wholly owned subsidiary of Honeywell International Inc., for the U.S. Department of Energy’s National Nuclear Security Administration under contract DE-NA0003525. SAND no: SAND2020-10057A.\nSlides"
  },
  {
    "objectID": "posts/2018-10-12.html",
    "href": "posts/2018-10-12.html",
    "title": "Introducing ggResidpanel: An R Package for Easy Visualization of Residuals",
    "section": "",
    "text": "As consultants on a wide variety of projects across many majors, a common oversight we encounter is a failure to examine the residuals. This is particularly true when the client is performing the analysis in R. We were inspired by the residual panel in SAS to create an R package that easily provides users with a similar panel of plots. The ggResidpanel package in R is intended to give a single view of diagnostic plots for checking the key underlying assumptions of linear models. A variety of options gives the user the ability to choose from a selection of plots to display in a window. This includes SAS’s default residual panel as well as R’s default plots for linear models. Other options have been included to ensure that this package can also be applied to deviance or Pearson residuals if the user inputs a generalized linear model. Cook’s D plots and interactive plots using Plotly are included to provide a straightforward process to identify outliers and influential points while connecting findings back to the data.\nSlides GitHub"
  },
  {
    "objectID": "posts/2021-04-16.html",
    "href": "posts/2021-04-16.html",
    "title": "WhoseEgg: A Shiny App for Identifying Invasive Carp Using Random Forests and Fish Egg Characteristics",
    "section": "",
    "text": "An introduction to the WhoseEgg app.\nSlides GitLab"
  },
  {
    "objectID": "posts/2018-05-08.html",
    "href": "posts/2018-05-08.html",
    "title": "Introducing ggResidpanel: An R Package for Easy Visualization of Residuals",
    "section": "",
    "text": "As consultants on a wide variety of projects across many majors, a common oversight we encounter is a failure to examine the residuals. This is particularly true when the client is performing the analysis in R. We were inspired by the residual panel in SAS to create an R package that easily provides users with a similar panel of plots. The ggResidpanel package in R is intended to give a single view of diagnostic plots for checking the key underlying assumptions of linear models. A variety of options gives the user the ability to choose from a selection of plots to display in a window. This includes SAS’s default residual panel as well as R’s default plots for linear models. Other options have been included to ensure that this package can also be applied to deviance or Pearson residuals if the user inputs a generalized linear model. Cook’s D plots and interactive plots using Plotly are included to provide a straightforward process to identify outliers and influential points while connecting findings back to the data.\nPoster"
  },
  {
    "objectID": "posts/2021-04-01.html",
    "href": "posts/2021-04-01.html",
    "title": "Tracing Trees: Visualizing Variability in the Architecture of Random Forest Trees Using Extensions of Trace Plots",
    "section": "",
    "text": "Random forests are a popular method for statistical applications with an objective of prediction. While an individual tree within a random forest provides a clear decision path for how a prediction is made, the ensemble of trees from the forest creates a complex decision process that is difficult to interpret. One approach used to gain insight into this decision process is visualization of the model. Various approaches have been taken to visualize random forests including trace plots developed by Simon Urbanek (https://link.springer.com/chapter/10.1007/978-3-540-33037-0_11). Trace plots depict the trees in a random forest using a structure similar to parallel coordinate plots that allows for a direct comparison of the trees. In this talk, I’ll describe trace plots and discuss my recent work on implementing and extending trace plots in R. I’ll also discuss my attempts to use trace plots to compare variability between clusters of trees in a random forest and visualizing representative or summary trees in the context of tree variability.\nSlides GitHub"
  },
  {
    "objectID": "posts/2020-10-02.html",
    "href": "posts/2020-10-02.html",
    "title": "A Statistical Consultant’s Perspective on Getting Help with R",
    "section": "",
    "text": "Everyone runs into problems when writing code in R (even statisticians). Sometimes the problems are small picture such as bugs in the code. Other times the problems are large picture such as how to implement an analysis all together. In this talk, we will provide a statistical consultant’s perspective on getting help with R. We’ll tell about the resources our consulting group provides to ISU graduate students who need help with R code and/or statistical analysis for a research project. We’ll also cover resources for helping yourself, internet resources for asking questions about R, and tips for practicing a good work flow in R that will hopefully help to avoid problems.\nSlides GitHub"
  },
  {
    "objectID": "posts/2019-10-04.html",
    "href": "posts/2019-10-04.html",
    "title": "ggResidpanel: Easy Creation of Panels of Diagnostics Plots",
    "section": "",
    "text": "Overview and tutorial on ggResidpanel.\nSlides GitHub"
  },
  {
    "objectID": "posts/2020-04-10.html",
    "href": "posts/2020-04-10.html",
    "title": "An Overview of Visualization Techniques for Explainable Machine Learning",
    "section": "",
    "text": "Machine learning models are excellent predictors, but it is impractical to interpret many of these models. Despite this impracticality, it is important to be able to explain predictions to assess and validate models. As a result, a field of research has recently developed in the explainability of machine learning models. In this talk, I will provide an overview of explainable machine learning with a focus on visualization methods. I will discuss philosophies of “explainability”, model agnostic and model specific visualization methods, and code for creating some of the visualizations in R. I hope that this talk will provide listeners with an introduction to explainable machine learning and resources to learn more if desired.\nSlides GitHub"
  },
  {
    "objectID": "posts/2023-06-22.html",
    "href": "posts/2023-06-22.html",
    "title": "Feature Importance with Deep Echo State Models",
    "section": "",
    "text": "Climate change due to human activity is considered a serious threat to our future. Climate intervention methods, such as solar radiation management, to reduce the negative impacts of climate change are becoming a real possibility. The development of algorithmic methods for understanding the short-term and long-term impacts of such events on climate change will help inform decision makers. Deep ensemble echo-state network (D-EESN) models may provide a route to assist with modeling the dynamic climate impacts. D-EESN models offer increased computational efficiency over other statistical spatio-temporal methods and provide uncertainty quantification through bootstrapping. However, D-EESN models are currently only able to provide forecasts and lack general interpretability. We are interested in developing methodology for understanding the relationships between the D-EESN inputs and outputs to help identify early indicators of significant climate impacts. We propose a variable importance technique for D-EESNs that returns the temporal importance of an input variable on forecasts. We demonstrate our methodology on reanalysis data that includes the 1991 eruption of Mount Pinatubo. We forecast stratospheric temperature given lagged stratospheric temperature and aerosol optical depth, and we use the proposed variable importance to capture the relationships between variables and how those relationships change over time.\nSlides GitLab"
  },
  {
    "objectID": "posts/2019-12-03.html",
    "href": "posts/2019-12-03.html",
    "title": "Visual Diagnostics of a Model Explainer: Tools for the Assessment of LIME Explanations",
    "section": "",
    "text": "A desire to be able to interpret machine learning models has led to an area of research focused on providing explanations for predictions made by black-box models. One method that has resulted from this area of research is LIME (Ribeiro et. al. 2016). LIME stands for local interpretable model-agnostic explanations. The method provides an explanation for a black box prediction by using an interpretable model, referred to as an explainer model, to approximate the complex black-box model in a local region around a prediction of interest. The quality of the explanation produced by LIME will depend on how good of an approximation the interpretable model is to the complex model. Currently, few tools have been provided to assess this approximation. We are developing visualizations that diagnose the explanation produced by LIME. In this talk, I will provide a brief overview of LIME, motivate the importance of the assessing LIME explanations, and introduce our diagnostic visualizations.\nSlides GitHub"
  },
  {
    "objectID": "posts/2022-07-11.html",
    "href": "posts/2022-07-11.html",
    "title": "Tracing Trees: Visualizing Random Forest Tree Variability with Trace Plots",
    "section": "",
    "text": "An introduction to trace plots and overview of my research on trace plots.\nSlides GitLab"
  },
  {
    "objectID": "posts/2020-11-20.html",
    "href": "posts/2020-11-20.html",
    "title": "Explaining Black Box Machine Learning Models",
    "section": "",
    "text": "An overview of explainable machine learning presented along with Xiaodan (Annie) Lyu.\nSlides"
  },
  {
    "objectID": "papers.html#section",
    "href": "papers.html#section",
    "title": "Papers",
    "section": "2018",
    "text": "2018\nCarlos Llosa. “Tensor on tensor regression with tensor normal errors and tensor network states on the regression parameter” 2018. Iowa State Digital Library. https://dr.lib.iastate.edu/handle/20.500.12876/17174"
  },
  {
    "objectID": "papers.html#section-1",
    "href": "papers.html#section-1",
    "title": "Papers",
    "section": "2022",
    "text": "2022\nAusdemore, M. A., A. McCombs, D. Ries, A. Zhang, K. Shuler, K. Goode, J. D. Tucker, and J. G. Huerta. 2022. A Probabilistic Inverse “Prediction Method for Predicting Plutonium Processing Conditions”. Frontiers in Nuclear Engineering-Nuclear Materials. https://doi.org/10.3389/fnuen.2022.1083164"
  },
  {
    "objectID": "papers.html#section-2",
    "href": "papers.html#section-2",
    "title": "Papers",
    "section": "2021",
    "text": "2021\nGoode, K. and H. Hofmann. “Visual diagnostics of an explainer model: Tools for the assessment of LIME explanations.” 2021. Stat Anal Data Min: The ASA Data Sci Journal 14:185–200. https://doi.org/10.1002/sam.11500. GitHub."
  },
  {
    "objectID": "papers.html#section-3",
    "href": "papers.html#section-3",
    "title": "Papers",
    "section": "2020",
    "text": "2020\nGoode, K., D. Ries, and J. Zollweg. “Explaining Neural Networks with Functional Data Using PCA and Feature Importance”. AAAI 2020 Fall Symposium on AI in the Government and Public Sector. November 13-14, 2020. https://arxiv.org/abs/2010.12063. YouTube Video.\nDixon, P.M., K. Goode, C. Lay. 2020. “Profile likelihood confidence intervals for ECx”. Iowa State Digital Library. Statistics Technical Reports. https://lib.dr.iastate.edu/stat_las_reports/1\nBall, E.E., K. Goode, and M.J. Weber. 2020. “Effects of Transport Duration and Water Quality on Age-0 Walleye Stress and Survival”. North American Journal of Aquaculture 82:33–42. https://doi.org/10.1002/naaq.10114."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Carlos Llosa",
    "section": "",
    "text": "PhD an M.S. in statistics from Iowa State University,\nB.S. in mathematics from Lawrence University.\nMy PhD adviser was Heike Hofmann, and\nmy dissertation focused on visualization techniques for explainability of machine learning (Visual diagnostics for explaining machine learning models).\nI currently work for Sandia National Laboratories as a research and development statistician.\nMy resume and CV are available here:\n\nResume (PDF version)\nCV\n\n\n\n\nEmail: cjllosa@sandia.gov\nPhone: 505-844-2540\nMailing Address:\n\nStatistical Sciences\nSandia National Laboratories\nPO Box 5800 MS 0829\nAlbuquerque, NM 87185"
  },
  {
    "objectID": "software.html",
    "href": "software.html",
    "title": "Software",
    "section": "",
    "text": "totr\n\n\n\n totr \n\ntotr is an R package\nHere is an example panel of diagnostic plots created using ggResidpanel.\n\n2+2\n\n[1] 4"
  },
  {
    "objectID": "presentations.html",
    "href": "presentations.html",
    "title": "Presentations",
    "section": "",
    "text": "Nov 9, 2017\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2023-07-22.html",
    "href": "posts/2023-07-22.html",
    "title": "Characterizing climate pathways using feature importance on echo state networks",
    "section": "",
    "text": "Talk given at JSM in Toronto, Canada in the topic-contributed session ‘Deep learning for climate change: forecasts, mitigation, and adaption’\nClimate change due to human activity is considered a serious threat to our future. Climate intervention methods, such as solar radiation management, to reduce the negative impacts of climate change are becoming a real possibility. The development of algorithmic methods for understanding the short-term and long-term impacts of such events on climate change will help inform decision makers. Deep ensemble echo-state network (D-EESN) models may provide a route to assist with modeling the dynamic climate impacts. D-EESN models offer increased computational efficiency over other statistical spatio-temporal methods and provide uncertainty quantification through bootstrapping. However, D-EESN models are currently only able to provide forecasts and lack general interpretability. We are interested in developing methodology for understanding the relationships between the D-EESN inputs and outputs to help identify early indicators of significant climate impacts. We propose a variable importance technique for D-EESNs that returns the temporal importance of an input variable on forecasts. We demonstrate our methodology on reanalysis data that includes the 1991 eruption of Mount Pinatubo. We forecast stratospheric temperature given lagged stratospheric temperature and aerosol optical depth, and we use the proposed variable importance to capture the relationships between variables and how those relationships change over time.\nSlides GitLab"
  },
  {
    "objectID": "posts/2023-08-08.html",
    "href": "posts/2023-08-08.html",
    "title": "Characterizing climate pathways using feature importance on echo state networks",
    "section": "",
    "text": "Climate change due to human activity is considered a serious threat to our future. Climate intervention methods, such as solar radiation management, to reduce the negative impacts of climate change are becoming a real possibility. The development of algorithmic methods for understanding the short-term and long-term impacts of such events on climate change will help inform decision makers. Deep ensemble echo-state network (D-EESN) models may provide a route to assist with modeling the dynamic climate impacts. D-EESN models offer increased computational efficiency over other statistical spatio-temporal methods and provide uncertainty quantification through bootstrapping. However, D-EESN models are currently only able to provide forecasts and lack general interpretability. We are interested in developing methodology for understanding the relationships between the D-EESN inputs and outputs to help identify early indicators of significant climate impacts. We propose a variable importance technique for D-EESNs that returns the temporal importance of an input variable on forecasts. We demonstrate our methodology on reanalysis data that includes the 1991 eruption of Mount Pinatubo. We forecast stratospheric temperature given lagged stratospheric temperature and aerosol optical depth, and we use the proposed variable importance to capture the relationships between variables and how those relationships change over time.\nSlides GitLab"
  },
  {
    "objectID": "posts/2021-11-09.html",
    "href": "posts/2021-11-09.html",
    "title": "Reduced-Rank Tensor-on-Tensor Regression and Tensor-Variate ANOVA",
    "section": "",
    "text": "LIME (Local Interpretable Model-agnostic Explanations) is a method that explains how black box models determine individual predictions. It was developed by computer scientists at the University of Washington and implemented in Python, and recently, Thomas Pedersen developed the R package lime that allows R users to implement the procedure. In this talk, I will explain the motivation for LIME, discuss how it works, and show examples using LIME in R. Additionally, I will encourage participation as we work through an example the creators of LIME used to test the usefulness of LIME, so please bring your laptop if possible.\nSlides GitHub"
  }
]